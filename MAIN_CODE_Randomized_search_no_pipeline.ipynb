{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efe4ec86",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\ritwik kashyap\\appdata\\roaming\\python\\python310\\site-packages (0.11.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\ritwik kashyap\\appdata\\roaming\\python\\python310\\site-packages (from imbalanced-learn) (1.9.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\ritwik kashyap\\appdata\\roaming\\python\\python310\\site-packages (from imbalanced-learn) (1.24.3)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\ritwik kashyap\\appdata\\roaming\\python\\python310\\site-packages (from imbalanced-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ritwik kashyap\\appdata\\roaming\\python\\python310\\site-packages (from imbalanced-learn) (3.2.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.1.1)\n"
     ]
    }
   ],
   "source": [
    "# !pip install -U imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2588d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from scipy.stats import loguniform\n",
    "from time import time \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.filters.rank import entropy\n",
    "from skimage.morphology import disk\n",
    "from skimage.filters import sobel\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "from skimage.feature import canny\n",
    "from skimage.filters import median\n",
    "from skimage.restoration import denoise_bilateral\n",
    "\n",
    "from skimage.filters import prewitt_h, prewitt_v\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30e95607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref : https://www.tutorialkart.com/opencv/python/opencv-python-resize-image/#gsc.tab=0\n",
    "\n",
    "# DOWNSCALE BY 50% : (480,499) = size\n",
    "def downsample_image(img):\n",
    "    scale_percent = 20 \n",
    "    width = int(img.shape[1] * scale_percent / 100)\n",
    "    height = int(img.shape[0] * scale_percent / 100)\n",
    "    dim = (width, height)\n",
    "\n",
    "    resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "    return resized\n",
    " \n",
    "def upsample_image(img):   # To be used after prediction\n",
    "    scale_percent = 500 \n",
    "    width = int(img.shape[1] * scale_percent / 100)\n",
    "    height = int(img.shape[0] * scale_percent / 100)\n",
    "    dim = (width, height)\n",
    "\n",
    "    resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "    return resized\n",
    "\n",
    "def find_segfile_of_image(image,segmentations):\n",
    "        image_name = image.split(\".\")[0]\n",
    "        for seg in segmentations:\n",
    "            if image_name in seg:\n",
    "                return seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23d6763a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PREPROCESSING FUNCTION\n",
    "def preprocess_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # check if size is correct \n",
    "    # 1) Convert to gray scale\n",
    "    # 2) Normalize \n",
    "    # 3) Downsample image to 20%\n",
    "    \n",
    "    if(img.shape[0] != 960):\n",
    "        print(\"Change shape\")\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    final_img = gray_img/255.0\n",
    "    final_img = downsample_image(gray_img)\n",
    "    \n",
    "    return final_img\n",
    "\n",
    "def preprocess_seg_map(seg_path):\n",
    "    # reading array \n",
    "    seg_map = cv2.imread(seg_path,cv2.IMREAD_GRAYSCALE)\n",
    "    # Convert from bool to uint8\n",
    "    seg_map = seg_map.astype(np.uint8)\n",
    "    # convert the max value pixel to 1 (To create a binary seg map)\n",
    "    seg_map[seg_map == 255] = 1\n",
    "    \n",
    "    # Downsample the seg_map by 50%\n",
    "    seg_map = downsample_image(seg_map)\n",
    "    return seg_map\n",
    "\n",
    "def extract_features(gray_img,seg_map):\n",
    "    radius = 1\n",
    "    entropy_img = entropy(gray_img,disk(radius))\n",
    "    \n",
    "    sigma = 5  \n",
    "    gauss_image = gaussian_filter(gray_img, sigma=sigma) #### (APPLIED ON COLOR ORIGINALLY)\n",
    "    sobel_filtered = sobel(gray_img) \n",
    "    \n",
    "    edges = canny(gray_img)\n",
    "    \n",
    "    median_filtered = median(gray_img)                               ##### (APPLIED ON COLOR ORIGINALLY)\n",
    "    \n",
    "    bilateral_filtered = denoise_bilateral(gray_img,channel_axis=-1,multichannel=False) ##### (APPLIED ON COLOR ORIGINALLY)\n",
    "    \n",
    "    prewitt_horizontal = prewitt_h(gray_img)\n",
    "    prewitt_vertical = prewitt_v(gray_img)\n",
    "    \n",
    "    pixel_feature = gray_img.reshape(-1).reshape(-1, 1)                        #1\n",
    "    entropy_feature = entropy_img.reshape(-1).reshape(-1, 1)                   #2\n",
    "    gauss_feature = gauss_image.reshape(-1).reshape(-1, 1)                     #3\n",
    "    sobel_feature = sobel_filtered.reshape(-1).reshape(-1, 1)                  #4\n",
    "    edges_feature = edges.reshape(-1).reshape(-1, 1)                           #5\n",
    "    median_feature = median_filtered.reshape(-1).reshape(-1, 1)                #6\n",
    "    bilateral_feature = bilateral_filtered.reshape(-1).reshape(-1, 1)          #7\n",
    "    prewitt_horizontal_feature = prewitt_horizontal.reshape(-1).reshape(-1, 1) #8\n",
    "    prewitt_vertical_feature = prewitt_vertical.reshape(-1).reshape(-1, 1)     #9\n",
    "    \n",
    "    label = seg_map.reshape(-1).reshape(-1, 1) \n",
    "    \n",
    "    feature_matrix = np.hstack((pixel_feature,entropy_feature,gauss_feature,\n",
    "                               sobel_feature,edges_feature,median_feature,\n",
    "                               bilateral_feature,prewitt_horizontal_feature,\n",
    "                               prewitt_vertical_feature,label))\n",
    "    return feature_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72a6595",
   "metadata": {},
   "source": [
    "#### PREPROCESSING AND FEATURE EXTRACTION \n",
    "\n",
    "1) Preprocessing : \n",
    "    \n",
    "    (a) Conversion to gray scale (For feature extraction)\n",
    "    \n",
    "    (b) Resizing to 150x150 if not training in 960x999 \n",
    "    \n",
    "    (c) Normalizing : divide by 255.0\n",
    "    \n",
    "2) Feature extraction\n",
    "\n",
    "   Features:-\n",
    "    (1) Entropy  (TEXTURE)\n",
    "    \n",
    "    (2) Sobel    \n",
    "    \n",
    "    (3) Gaussian          \n",
    "    \n",
    "    (4) Canny edge detector\n",
    "    \n",
    "    (5) Median filter\n",
    "    \n",
    "    (6) Bilateral filter\n",
    "    \n",
    "    (7) Prewitt vertical filter\n",
    "    \n",
    "    (8) Prewitt horizontal filter\n",
    "    \n",
    "    (9) Pixel intensity \n",
    "    \n",
    "    CAN ADD GABOR FEATURES TO THIS AS WELL\n",
    "    \n",
    "    (10)Pixel label (1 or 0)\n",
    "    \n",
    "    PROBLEM : 1) Some features are found on gray scale some on color \n",
    "                 afterwards we get feature maps of different channels\n",
    "                 How to flatten them to get consistent dimensions afterwards \n",
    "                 in order to get a feature vector for an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f5a9466",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix for image  Image_01L.jpg  :  (38208, 10)\n",
      "Feature matrix for image  Image_01R.jpg  :  (38208, 10)\n",
      "\n",
      "Final shape of data matrix :  (76416, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RITWIK KASHYAP\\AppData\\Local\\Temp\\ipykernel_42176\\3319276761.py:43: FutureWarning: `multichannel` is a deprecated argument name for `denoise_bilateral`. It will be removed in version 1.0. Please use `channel_axis` instead.\n",
      "  bilateral_filtered = denoise_bilateral(gray_img,channel_axis=-1,multichannel=False) ##### (APPLIED ON COLOR ORIGINALLY)\n"
     ]
    }
   ],
   "source": [
    "image_folder = \"IMAGES\"\n",
    "seg_folder = \"SEG1\"\n",
    "\n",
    "images = os.listdir(image_folder)\n",
    "segmentations = os.listdir(seg_folder)\n",
    "\n",
    "image_features_matrices_combined = []\n",
    "\n",
    "i = 0\n",
    "for image in images:\n",
    "    # 10 images considered\n",
    "    if(i == 2):\n",
    "        break\n",
    "    \n",
    "    # preprocessing image\n",
    "    image_path = os.path.join(image_folder,image)\n",
    "    gray_img = preprocess_image(image_path)\n",
    "    \n",
    "    \n",
    "    # preprocessing segmentation map\n",
    "    seg_name = find_segfile_of_image(image,segmentations)\n",
    "    seg_path = os.path.join(seg_folder,seg_name)\n",
    "    seg_map = preprocess_seg_map(seg_path)\n",
    "    \n",
    "    \n",
    "    # feature extraction    \n",
    "    feature_matrix = extract_features(gray_img,seg_map)\n",
    "    image_features_matrices_combined.append(feature_matrix)\n",
    "    \n",
    "    print(\"Feature matrix for image \",image,\" : \",feature_matrix.shape)\n",
    "    i+=1\n",
    "    \n",
    "print()\n",
    "Final_matrix = np.vstack(image_features_matrices_combined)\n",
    "print(\"Final shape of data matrix : \",Final_matrix.shape)\n",
    "\n",
    "#     print(\"dtype of image array : \",img.dtype)\n",
    "#     print(\"dtype of seg map : \",seg_map.dtype)\n",
    "#     dtype of image array :  uint8\n",
    "#     dtype of seg map :  uint8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b296d5a",
   "metadata": {},
   "source": [
    "#### TRAIN, VALIDATION AND TEST SPLITS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "baa10332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382075</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382076</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382077</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382078</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382079</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>382080 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0    1    2    3    4    5    6    7    8    9\n",
       "0       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "1       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "2       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "3       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "4       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "...     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
       "382075  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "382076  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "382077  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "382078  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "382079  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "\n",
       "[382080 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(Final_matrix)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e81f8861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DataFrame contains non-zero values.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>28.0</td>\n",
       "      <td>2.321928</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.104576</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.155991</td>\n",
       "      <td>0.150327</td>\n",
       "      <td>-0.011765</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082</th>\n",
       "      <td>45.0</td>\n",
       "      <td>2.321928</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.081467</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.177210</td>\n",
       "      <td>0.113725</td>\n",
       "      <td>-0.005229</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083</th>\n",
       "      <td>42.0</td>\n",
       "      <td>2.321928</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.060380</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.181053</td>\n",
       "      <td>0.086275</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1.921928</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.030455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.169538</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>-0.010458</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282</th>\n",
       "      <td>40.0</td>\n",
       "      <td>2.321928</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.188996</td>\n",
       "      <td>0.001307</td>\n",
       "      <td>0.001307</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380790</th>\n",
       "      <td>82.0</td>\n",
       "      <td>2.321928</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.035430</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.250460</td>\n",
       "      <td>-0.036601</td>\n",
       "      <td>0.020915</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380989</th>\n",
       "      <td>76.0</td>\n",
       "      <td>2.321928</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.124417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.151533</td>\n",
       "      <td>-0.175163</td>\n",
       "      <td>-0.010458</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380990</th>\n",
       "      <td>79.0</td>\n",
       "      <td>2.321928</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.150151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.154587</td>\n",
       "      <td>-0.209150</td>\n",
       "      <td>0.009150</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381188</th>\n",
       "      <td>37.0</td>\n",
       "      <td>2.321928</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.025611</td>\n",
       "      <td>-0.308497</td>\n",
       "      <td>-0.023529</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381189</th>\n",
       "      <td>33.0</td>\n",
       "      <td>2.321928</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.217718</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.021414</td>\n",
       "      <td>-0.308497</td>\n",
       "      <td>0.002614</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27712 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1     2         3    4     5         6         7  \\\n",
       "900     28.0  2.321928  25.0  0.104576  1.0  28.0  0.155991  0.150327   \n",
       "1082    45.0  2.321928  27.0  0.081467  0.0  42.0  0.177210  0.113725   \n",
       "1083    42.0  2.321928  28.0  0.060380  0.0  42.0  0.181053  0.086275   \n",
       "1099    37.0  1.921928  28.0  0.030455  0.0  37.0  0.169538  0.044444   \n",
       "1282    40.0  2.321928  31.0  0.001961  0.0  45.0  0.188996  0.001307   \n",
       "...      ...       ...   ...       ...  ...   ...       ...       ...   \n",
       "380790  82.0  2.321928  61.0  0.035430  0.0  82.0  0.250460 -0.036601   \n",
       "380989  76.0  2.321928  54.0  0.124417  0.0  79.0  0.151533 -0.175163   \n",
       "380990  79.0  2.321928  53.0  0.150151  0.0  79.0  0.154587 -0.209150   \n",
       "381188  37.0  2.321928  48.0  0.216667  1.0  37.0  0.025611 -0.308497   \n",
       "381189  33.0  2.321928  47.0  0.217718  1.0  33.0  0.021414 -0.308497   \n",
       "\n",
       "               8    9  \n",
       "900    -0.011765  1.0  \n",
       "1082   -0.005229  1.0  \n",
       "1083    0.022222  1.0  \n",
       "1099   -0.010458  1.0  \n",
       "1282    0.001307  1.0  \n",
       "...          ...  ...  \n",
       "380790  0.020915  1.0  \n",
       "380989 -0.010458  1.0  \n",
       "380990  0.009150  1.0  \n",
       "381188 -0.023529  1.0  \n",
       "381189  0.002614  1.0  \n",
       "\n",
       "[27712 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_zero_df = df.eq(0).all().all()\n",
    "\n",
    "if is_zero_df:\n",
    "    print(\"The entire DataFrame is filled with 0's.\")\n",
    "else:\n",
    "    print(\"The DataFrame contains non-zero values.\")\n",
    "    \n",
    "filtered_df = df[df.iloc[:, -1] == 1]\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52d9d1b",
   "metadata": {},
   "source": [
    "#### Final_matrix : matrix that is to be used for training \n",
    "#### df : final df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92dc0a5f",
   "metadata": {},
   "source": [
    "#### TRAIN : VALIDATION : TEST SPLIT ( 70 : 15 : 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cadafe4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (61132, 10)\n",
      "X_test shape: (15284, 10)\n"
     ]
    }
   ],
   "source": [
    "# Random shuffle the matrix \n",
    "X = Final_matrix\n",
    "np.random.shuffle(X)\n",
    "\n",
    "n_samples = X.shape[0]\n",
    "\n",
    "train_ratio = 0.8\n",
    "test_ratio = 0.2\n",
    "\n",
    "n_train = int(train_ratio * n_samples)\n",
    "n_test = n_samples - n_train\n",
    "\n",
    "x_train = X[:n_train, :]\n",
    "x_test = X[n_train :, :]\n",
    "\n",
    "print(f\"X_train shape: {x_train.shape}\")\n",
    "print(f\"X_test shape: {x_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae97a778",
   "metadata": {},
   "source": [
    "#### CLASS IMBALANCE CHECK IN TRAIN MATRIX "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e75ba8f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples with class label 0: 56925\n",
      "Number of samples with class label 1: 4207\n"
     ]
    }
   ],
   "source": [
    "class_labels = x_train[:, -1]\n",
    "\n",
    "count_class_0 = np.count_nonzero(class_labels == 0)\n",
    "count_class_1 = np.count_nonzero(class_labels == 1)\n",
    "\n",
    "print(f\"Number of samples with class label 0: {count_class_0}\")\n",
    "print(f\"Number of samples with class label 1: {count_class_1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ed351ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Xtrain shape :  (61132, 9)\n",
      "Before Ytrain shape :  (61132,)\n",
      "\n",
      "Number of zeros in ytrain before :  56925\n",
      "Number of ones ytrain before :  4207\n",
      "\n",
      "Number of zeros in ytrain after : 56925\n",
      "Number of ones ytrain after : 56925\n",
      "\n",
      "x_train shape :  (113850, 9)\n",
      "y_train shape :  (113850,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train_features = x_train[:, :-1]\n",
    "# X_train_features_scaled = scaler.fit_transform(X_train_features)\n",
    "\n",
    "y_train_target = x_train[:, -1]\n",
    "\n",
    "print(\"Before Xtrain shape : \",x_train_features.shape)\n",
    "print(\"Before Ytrain shape : \",y_train_target.shape)\n",
    "print()\n",
    "\n",
    "count_zeros = np.count_nonzero(y_train_target == 0)\n",
    "count_ones = np.count_nonzero(y_train_target == 1)\n",
    "print(\"Number of zeros in ytrain before : \", count_zeros)\n",
    "print(\"Number of ones ytrain before : \", count_ones)\n",
    "print()\n",
    "############################### CLASS BALANCING USING SMOTE #############################33\n",
    "smote = SMOTE(random_state=42)\n",
    "x_train_resampled, y_train_resampled = smote.fit_resample(x_train_features, y_train_target)\n",
    "\n",
    "############################### COUNTING CLASS WISE SAMPLES #############################33\n",
    "\n",
    "count_zeros = np.count_nonzero(y_train_resampled == 0)\n",
    "count_ones = np.count_nonzero(y_train_resampled == 1)\n",
    "\n",
    "print(\"Number of zeros in ytrain after :\", count_zeros)\n",
    "print(\"Number of ones ytrain after :\", count_ones)\n",
    "print()\n",
    "############################### SHAPES OF TRAINING DATA ####################################\n",
    "print(\"x_train shape : \",x_train_resampled.shape)\n",
    "print(\"y_train shape : \",y_train_resampled.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ab5793",
   "metadata": {},
   "source": [
    "####                                                                       SUPPORT VECTOR MACHINES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7724f505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_resampled :-\n",
      "The array is C-contiguous.\n",
      "y_train_resampled :-\n",
      "The array is C-contiguous.\n"
     ]
    }
   ],
   "source": [
    "#Avoiding data copy: For SVC, SVR, NuSVC and NuSVR, \n",
    "#if the data passed to certain methods is not C-ordered \n",
    "#contiguous and double precision,it will be copied before calling \n",
    "#the underlying C implementation. You can check whether a given \n",
    "#numpy array is C-contiguous by inspecting its flags attribute.\n",
    "\n",
    "# checking if x_train resampled and y_train resampled are C-contigous\n",
    "def check_c_cont(arr):\n",
    "    if arr.flags['C_CONTIGUOUS']:\n",
    "        print(\"The array is C-contiguous.\")\n",
    "    else:\n",
    "        print(\"The array is not C-contiguous.\")\n",
    "\n",
    "print(\"x_train_resampled :-\")\n",
    "check_c_cont(x_train_resampled)\n",
    "\n",
    "print(\"y_train_resampled :-\")\n",
    "check_c_cont(y_train_resampled)\n",
    "\n",
    "# Setting C: C is 1 by default and it’s a reasonable default choice. \n",
    "#            If you have a lot of noisy observations you should decrease it: \n",
    "#            decreasing C corresponds to more regularization.\n",
    "\n",
    "# C will be set to 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e979dff",
   "metadata": {},
   "source": [
    "#### TRAINING : BALANCED CLASSES , 2 IMAGES : 30th December\n",
    "\n",
    "#### : 1) Support vector classifier  with Randomized search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26fc910",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the classifier to the training set\n",
      "[LibSVM]"
     ]
    }
   ],
   "source": [
    "print(\"Fitting the classifier to the training set\")\n",
    "t0 = time()\n",
    "\n",
    "param_grid = {\n",
    "    \"C\": loguniform(1e3, 1e5),\n",
    "    \"gamma\": loguniform(1e-4, 1e-1),\n",
    "    \"kernel\" : ['linear','poly']\n",
    "}\n",
    "\n",
    "clf = RandomizedSearchCV(\n",
    "    svm.SVC(C = 0.2, class_weight=\"balanced\", cache_size = 3000, verbose = True), param_grid, n_iter=10\n",
    ")\n",
    "\n",
    "clf = clf.fit(x_train_resampled, y_train_resampled)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print(\"Best estimator found by grid search:\")\n",
    "print(clf.best_estimator_)\n",
    "\n",
    "# clf_params = {'cv': None,\n",
    "#              'error_score': float('nan'),\n",
    "#              'estimator__C': 0.3,\n",
    "#              'estimator__break_ties': False,\n",
    "#              'estimator__cache_size': 3000,\n",
    "#              'estimator__class_weight': 'balanced',\n",
    "#              'estimator__coef0': 0.0,\n",
    "#              'estimator__decision_function_shape': 'ovr',\n",
    "#              'estimator__degree': 3,\n",
    "#              'estimator__gamma': 'scale',\n",
    "#              'estimator__kernel': 'rbf',\n",
    "#              'estimator__max_iter': -1,\n",
    "#              'estimator__probability': False,\n",
    "#              'estimator__random_state': None,\n",
    "#              'estimator__shrinking': True,\n",
    "#              'estimator__tol': 0.001,\n",
    "#              'estimator__verbose': True,\n",
    "#              'estimator': svm.SVC(class_weight='balanced'),\n",
    "#              'n_iter': 10,\n",
    "#              'n_jobs': None,\n",
    "#              'param_distributions': {'C': loguniform(1e3, 1e5),\n",
    "#               'gamma': loguniform(1e-4, 1e-1),\n",
    "#               'Kernel': ['linear', 'poly']},\n",
    "#              'pre_dispatch': '2*n_jobs',\n",
    "#              'random_state': None,\n",
    "#              'refit': True,\n",
    "#              'return_train_score': True,\n",
    "#              'scoring': None,\n",
    "#              'verbose': 1}\n",
    "\n",
    "# clf.set_params(**clf_params)\n",
    "# clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f526af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the model checkpoint \n",
    "\n",
    "joblib.dump(model, 'Trained_model_checkpoints/TM_3_301223_without_scaler_with_SMOTE_2Image_RandomizedSearch.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9d42b3",
   "metadata": {},
   "source": [
    "#### TEST SET ACCURACY "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629885a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_features = X_test[:, :-1]\n",
    "# X_test_features_scaled = scaler.transform(X_test_features)\n",
    "\n",
    "y_test_target = X_test[:, -1]\n",
    "\n",
    "y_pred = clf.predict(X_test_features)\n",
    "\n",
    "count_zeros = np.count_nonzero(y_pred == 0)\n",
    "count_ones = np.count_nonzero(y_pred == 1)\n",
    "\n",
    "print(\"Number of zeros:\", count_zeros)\n",
    "print(\"Number of ones:\", count_ones)\n",
    "\n",
    "accuracy = accuracy_score(y_test_target, y_pred)\n",
    "report = classification_report(y_test_target, y_pred,target_names=['Not Vein', 'Vein'])\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
